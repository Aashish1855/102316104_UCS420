{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12bf27bc",
   "metadata": {},
   "source": [
    "Q1. Write a unique paragraph (5-6 sentences) about your favorite topic (e.g., sports,\n",
    "technology, food, books, etc.).\n",
    "1. Convert text to lowercase and remove punctuation using re.\n",
    "2. Tokenize the text into words and sentences.\n",
    "3. Split using split() and word_tokenize() and compare how Python split and NLTK’s\n",
    "word_tokenize() differ.\n",
    "4. Remove stopwords (using NLTK's stopwords list).\n",
    "5. Display word frequency distribution (excluding stopwords)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f33fb5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      " Technology is evolving faster than ever. Artificial Intelligence is reshaping how we interact with machines. I love exploring new gadgets and learning about innovations. From smartphones to smart homes, tech is deeply embedded in our daily lives. It excites me to see how automation and data science are transforming industries.\n",
      "\n",
      "Cleaned Text:\n",
      " technology is evolving faster than ever artificial intelligence is reshaping how we interact with machines i love exploring new gadgets and learning about innovations from smartphones to smart homes tech is deeply embedded in our daily lives it excites me to see how automation and data science are transforming industries\n",
      "\n",
      "Sentences:\n",
      " ['Technology is evolving faster than ever.', 'Artificial Intelligence is reshaping how we interact with machines.', 'I love exploring new gadgets and learning about innovations.', 'From smartphones to smart homes, tech is deeply embedded in our daily lives.', 'It excites me to see how automation and data science are transforming industries.']\n",
      "\n",
      "Python split():\n",
      " ['technology', 'is', 'evolving', 'faster', 'than', 'ever', 'artificial', 'intelligence', 'is', 'reshaping', 'how', 'we', 'interact', 'with', 'machines', 'i', 'love', 'exploring', 'new', 'gadgets', 'and', 'learning', 'about', 'innovations', 'from', 'smartphones', 'to', 'smart', 'homes', 'tech', 'is', 'deeply', 'embedded', 'in', 'our', 'daily', 'lives', 'it', 'excites', 'me', 'to', 'see', 'how', 'automation', 'and', 'data', 'science', 'are', 'transforming', 'industries']\n",
      "\n",
      "NLTK word_tokenize():\n",
      " ['technology', 'is', 'evolving', 'faster', 'than', 'ever', 'artificial', 'intelligence', 'is', 'reshaping', 'how', 'we', 'interact', 'with', 'machines', 'i', 'love', 'exploring', 'new', 'gadgets', 'and', 'learning', 'about', 'innovations', 'from', 'smartphones', 'to', 'smart', 'homes', 'tech', 'is', 'deeply', 'embedded', 'in', 'our', 'daily', 'lives', 'it', 'excites', 'me', 'to', 'see', 'how', 'automation', 'and', 'data', 'science', 'are', 'transforming', 'industries']\n",
      "\n",
      "Stopwords Removed:\n",
      " ['technology', 'evolving', 'faster', 'ever', 'artificial', 'intelligence', 'reshaping', 'interact', 'machines', 'love', 'exploring', 'new', 'gadgets', 'learning', 'innovations', 'smartphones', 'smart', 'homes', 'tech', 'deeply', 'embedded', 'daily', 'lives', 'excites', 'see', 'automation', 'data', 'science', 'transforming', 'industries']\n",
      "\n",
      "Word Frequency Distribution:\n",
      " Counter({'technology': 1, 'evolving': 1, 'faster': 1, 'ever': 1, 'artificial': 1, 'intelligence': 1, 'reshaping': 1, 'interact': 1, 'machines': 1, 'love': 1, 'exploring': 1, 'new': 1, 'gadgets': 1, 'learning': 1, 'innovations': 1, 'smartphones': 1, 'smart': 1, 'homes': 1, 'tech': 1, 'deeply': 1, 'embedded': 1, 'daily': 1, 'lives': 1, 'excites': 1, 'see': 1, 'automation': 1, 'data': 1, 'science': 1, 'transforming': 1, 'industries': 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aashishsharma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aashishsharma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "text = \"Technology is evolving faster than ever. Artificial Intelligence is reshaping how we interact with machines. I love exploring new gadgets and learning about innovations. From smartphones to smart homes, tech is deeply embedded in our daily lives. It excites me to see how automation and data science are transforming industries.\"\n",
    "cleaned_text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "sentences = sent_tokenize(text)\n",
    "word_tokens_nltk = word_tokenize(cleaned_text)\n",
    "word_tokens_split = cleaned_text.split()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in word_tokens_nltk if word not in stop_words]\n",
    "word_freq = Counter(filtered_words)\n",
    "print(\"Original Text:\\n\", text)\n",
    "print(\"\\nCleaned Text:\\n\", cleaned_text)\n",
    "print(\"\\nSentences:\\n\", sentences)\n",
    "print(\"\\nPython split():\\n\", word_tokens_split)\n",
    "print(\"\\nNLTK word_tokenize():\\n\", word_tokens_nltk)\n",
    "print(\"\\nStopwords Removed:\\n\", filtered_words)\n",
    "print(\"\\nWord Frequency Distribution:\\n\", word_freq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d098e7a",
   "metadata": {},
   "source": [
    "Q2. Using the same paragraph from Q1:\n",
    "1. Extract all words with only alphabets using re.findall()\n",
    "2. Remove stop words using NLTK’s stopword list\n",
    "3. Perform stemming with PorterStemmer\n",
    "4. Perform lemmatization with WordNetLemmatizer\n",
    "5. Compare the stemmed and lemmatized outputs and explain when you’d prefer one over\n",
    "the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de9c3d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words with only alphabets: ['technology', 'is', 'evolving', 'faster', 'than', 'ever', 'artificial', 'intelligence', 'is', 'reshaping', 'how', 'we', 'interact', 'with', 'machines', 'i', 'love', 'exploring', 'new', 'gadgets', 'and', 'learning', 'about', 'innovations', 'from', 'smartphones', 'to', 'smart', 'homes', 'tech', 'is', 'deeply', 'embedded', 'in', 'our', 'daily', 'lives', 'it', 'excites', 'me', 'to', 'see', 'how', 'automation', 'and', 'data', 'science', 'are', 'transforming', 'industries']\n",
      "Words after removing stop words: ['technology', 'evolving', 'faster', 'ever', 'artificial', 'intelligence', 'reshaping', 'interact', 'machines', 'love', 'exploring', 'new', 'gadgets', 'learning', 'innovations', 'smartphones', 'smart', 'homes', 'tech', 'deeply', 'embedded', 'daily', 'lives', 'excites', 'see', 'automation', 'data', 'science', 'transforming', 'industries']\n",
      "Stemmed words: ['technolog', 'evolv', 'faster', 'ever', 'artifici', 'intellig', 'reshap', 'interact', 'machin', 'love', 'explor', 'new', 'gadget', 'learn', 'innov', 'smartphon', 'smart', 'home', 'tech', 'deepli', 'embed', 'daili', 'live', 'excit', 'see', 'autom', 'data', 'scienc', 'transform', 'industri']\n",
      "Lemmatized words: ['technology', 'evolving', 'faster', 'ever', 'artificial', 'intelligence', 'reshaping', 'interact', 'machine', 'love', 'exploring', 'new', 'gadget', 'learning', 'innovation', 'smartphones', 'smart', 'home', 'tech', 'deeply', 'embedded', 'daily', 'life', 'excites', 'see', 'automation', 'data', 'science', 'transforming', 'industry']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aashishsharma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aashishsharma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Aashishsharma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "text = \"Technology is evolving faster than ever. Artificial Intelligence is reshaping how we interact with machines. I love exploring new gadgets and learning about innovations. From smartphones to smart homes, tech is deeply embedded in our daily lives. It excites me to see how automation and data science are transforming industries.\"\n",
    "\n",
    "words = re.findall(r'\\b[a-zA-Z]+\\b', text.lower())\n",
    "print(\"Words with only alphabets:\", words)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in words if word not in stop_words]\n",
    "print(\"Words after removing stop words:\", filtered_words)\n",
    "\n",
    "ps = PorterStemmer()\n",
    "stemmed_words = [ps.stem(word) for word in filtered_words]\n",
    "print(\"Stemmed words:\", stemmed_words)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "print(\"Lemmatized words:\", lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf49f187",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47491b34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
